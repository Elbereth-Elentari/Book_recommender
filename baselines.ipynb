{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baselines.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Elbereth-Elentari/Book_recommender/blob/master/baselines.ipynb",
      "authorship_tag": "ABX9TyPq3/7S2leA4YHenoI4tZqt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elbereth-Elentari/Book_recommender/blob/master/baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Vv34on2y2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix, recall_score"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t6TsD4h3FOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_input(jl_file):\n",
        "    catalogue_df = pd.read_json('/content/drive/My Drive/Library_catalogue_preprocessed.jl', lines=True, orient='records').fillna('')\n",
        "    catalogue_df = catalogue_df[catalogue_df['interesting'] != '']\n",
        "    catalogue_df.replace({'interesting':'yes'}, 1, inplace=True)\n",
        "    catalogue_df.replace({'interesting':'no'}, 0, inplace=True)\n",
        "\n",
        "    def join_tokens(row):\n",
        "        return ' '.join(row['tokens'])\n",
        "\n",
        "    catalogue_df['tokens'] = catalogue_df.apply(join_tokens, axis=1)\n",
        "    return catalogue_df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqtsnHrl3gQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_datasets(catalogue_df):\n",
        "    X = catalogue_df[['year', 'pages', 'tokens']]\n",
        "    y = catalogue_df['interesting']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "    scaler = MinMaxScaler().fit(X_train[['year', 'pages']])\n",
        "    X_train_scaled = scaler.transform(X_train[['year', 'pages']])\n",
        "    X_test_scaled = scaler.transform(X_test[['year', 'pages']])\n",
        "    cvect = CountVectorizer()\n",
        "    X_train_counts = cvect.fit_transform(X_train['tokens'])\n",
        "    X_test_counts = cvect.transform(X_test['tokens'])\n",
        "\n",
        "    tfidf = TfidfTransformer(use_idf=False)\n",
        "    X_train_transformed = tfidf.fit_transform(X_train_counts)\n",
        "    X_test_transformed = tfidf.transform(X_test_counts)\n",
        "\n",
        "    X_train_array = X_train_transformed.toarray()\n",
        "    X_test_array = X_test_transformed.toarray()\n",
        "\n",
        "    X_final = np.hstack((X_train_array, X_train_scaled))\n",
        "    X_final_test = np.hstack((X_test_array, X_test_scaled))\n",
        "\n",
        "    for iteration in range(50):\n",
        "        X_final = np.hstack((X_final, X_train_scaled))\n",
        "        X_final_test = np.hstack((X_final_test, X_test_scaled))\n",
        "    return X_final, X_final_test, y_train, y_test"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipq7fS9CAGCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn(X_train, X_test, y_train, y_test):\n",
        "    best_k = 0\n",
        "    best_recall = 0\n",
        "\n",
        "    for k in range(1,15):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train)\n",
        "        recall = recall_score(y_test, knn.predict(X_test))\n",
        "        if recall > best_recall:\n",
        "            best_recall = recall\n",
        "            best_k = k\n",
        "    best_knn = KNeighborsClassifier(n_neighbors=best_k).fit(X_train, y_train)\n",
        "    print('KNN')\n",
        "    print(confusion_matrix(y_test, best_knn.predict(X_test)))\n",
        "    return f1_score(y_test, best_knn.predict(X_test))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmQTy5nQGtfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(X_train, X_test, y_train, y_test):\n",
        "    logreg = LogisticRegression().fit(X_train, y_train)\n",
        "    return accuracy_score(y_test, logreg.predict(X_test))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckAKX6CfKUm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVC_linear(X_train, X_test, y_train, y_test):\n",
        "    svc = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "    return accuracy_score(y_test, svc.predict(X_test))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAixqa0RfpM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVC_rbf(X_train, X_test, y_train, y_test):\n",
        "    svc_rbf = SVC(kernel='rbf', gamma=1).fit(X_train, y_train)\n",
        "    return accuracy_score(y_test, svc_rbf.predict(X_test))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2iJmUH-iS5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Naive_Bayes_multinomial(X_train, X_test, y_train, y_test):\n",
        "    multi_nb = MultinomialNB(alpha=0.1).fit(X_train, y_train)\n",
        "    return accuracy_score(y_test, multi_nb.predict(X_test))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnNZWO0FoR9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Naive_Bayes_Gaussian(X_train, X_test, y_train, y_test):\n",
        "    gauss_nb = GaussianNB().fit(X_train, y_train)\n",
        "    return accuracy_score(y_test, gauss_nb.predict(X_test))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqIp4EowpF-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "fd13af4a-3d3d-4a3f-eea8-2ffcedd6baea"
      },
      "source": [
        "def calculate_baselines():\n",
        "    baselines_df = pd.DataFrame(columns=['en', 'pl'])\n",
        "    models = {'KNN':knn, 'logistic regression':logistic_regression,\n",
        "              'SVC linear':SVC_linear, 'SVC rbf':SVC_rbf,\n",
        "              'Naive Bayes multinomial':Naive_Bayes_multinomial,\n",
        "              'Naive Bayes Gaussian':Naive_Bayes_Gaussian}\n",
        "    catalogue = read_input('/content/drive/My Drive/Library_catalogue_preprocessed.jl')\n",
        "    for language in ['en', 'pl']:\n",
        "        print(language)\n",
        "        catalogue_lang = catalogue[catalogue['language'] == language]\n",
        "        data = create_datasets(catalogue_lang)\n",
        "        for model in models:\n",
        "            baselines_df.loc[model, language] = models[model](*data)\n",
        "\n",
        "    return baselines_df\n",
        "\n",
        "calculate_baselines()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en\n",
            "KNN\n",
            "[[62 10]\n",
            " [ 8 11]]\n",
            "pl\n",
            "KNN\n",
            "[[231  39]\n",
            " [ 50  45]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>pl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.502793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logistic regression</th>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.772603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC linear</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.808219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC rbf</th>\n",
              "      <td>0.879121</td>\n",
              "      <td>0.764384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes multinomial</th>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.791781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes Gaussian</th>\n",
              "      <td>0.78022</td>\n",
              "      <td>0.745205</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               en        pl\n",
              "KNN                          0.55  0.502793\n",
              "logistic regression      0.846154  0.772603\n",
              "SVC linear               0.857143  0.808219\n",
              "SVC rbf                  0.879121  0.764384\n",
              "Naive Bayes multinomial  0.824176  0.791781\n",
              "Naive Bayes Gaussian      0.78022  0.745205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uHsYfZ9dMJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}