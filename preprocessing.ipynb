{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "mount_file_id": "1L9mGtJ2u9AlfPDnlOSpY83ic1atfUqcl",
      "authorship_tag": "ABX9TyOjZxOWhuuxP9paZGvaj4NS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elbereth-Elentari/Book_recommender/blob/master/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkV187winJaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install spacy==2.3.0\n",
        "!pip3 install spacy_langdetect\n",
        "!pip3 install tqdm\n",
        "import spacy.cli\n",
        "spacy.cli.download('en_core_web_lg')\n",
        "spacy.cli.download('pl_core_news_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-sS5tw-rHd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy_langdetect import LanguageDetector\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "import pl_core_news_lg\n",
        "nlp_pl = pl_core_news_lg.load()\n",
        "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
        "\n",
        "from ipykernel import kernelapp as app\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import string"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehab8THHl1nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat = pd.read_json('/content/drive/My Drive/Library_catalogue.jl', lines=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNula6hGrURy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_language(df):\n",
        "    language = []\n",
        "    for doc in tqdm(nlp.pipe(df['title'].values, batch_size=1000), desc='Detecting language', total=len(df)):\n",
        "        if doc.is_parsed:\n",
        "            if doc._.language['language'] == 'en': language.append('en')\n",
        "            else: language.append('pl')\n",
        "        else: language.append('')\n",
        "\n",
        "    df['language'] = language\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB6N5P5WrjrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(input_df):\n",
        "    preprocessed_df = detect_language(input_df)\n",
        "\n",
        "    for lang in ['pl', 'en']:\n",
        "        if lang == 'en': model = nlp\n",
        "        elif lang == 'pl': model = nlp_pl\n",
        "\n",
        "        df = input_df[input_df['language'] == lang]\n",
        "        stopwords = model.Defaults.stop_words\n",
        "        preprocessed = []\n",
        "        for doc in tqdm(model.pipe(df['title'].values, batch_size=200), desc=f'Preprocessing {lang}', total=len(df)):\n",
        "            if doc.is_parsed:\n",
        "                tokens = [token.lemma_.lower() for token in doc if (token.text.lower() not in stopwords and token.text not in string.punctuation)]\n",
        "                if len(tokens) > 0: preprocessed.append(tokens)\n",
        "                else: preprocessed.append('preprocessing_fail')\n",
        "            else: preprocessed.append('preprocessing_fail')\n",
        "\n",
        "        df['tokens'] = preprocessed\n",
        "        df = df[df['tokens'] != 'preprocessing_fail']\n",
        "        preprocessed_df = preprocessed_df.append(df)\n",
        "    return preprocessed_df"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_VfKej5qOJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat.sort_values(by='year', ascending=False, inplace=True)\n",
        "cat.drop_duplicates(subset='title', inplace=True)\n",
        "cat = preprocess(cat)\n",
        "cat.to_json('/content/drive/My Drive/Library_catalogue_preprocessed.jl', lines=True, orient='records')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}